{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "專案2ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOKHUwza8a7PyWrvtEGBW7f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShawnFromChineseTaipei/class_test/blob/main/%E5%B0%88%E6%A1%882ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from re import L\n",
        "from time import asctime, localtime, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import lightgbm as lgbm\n",
        "\n",
        "pd.set_option('display.max_columns', 25)\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "\n",
        "x_train = pd.read_csv('/content/train.csv')\n",
        "x_test = pd.read_csv('/content/test.csv')\n",
        "\n",
        "submission = pd.DataFrame(\n",
        "    columns=[\"PassengerId\", \"Transported\"], data=x_test[\"PassengerId\"])\n",
        "\n",
        "y_train = x_train[\"Transported\"]\n",
        "x_train = x_train.drop(columns=[\"Transported\", ])\n",
        "\n",
        "float_features = [\"Age\", \"RoomService\",\n",
        "                  \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"most_spent\", \"least_spent\", \"std_spent\", \"total_spent\"]\n",
        "\n",
        "label_encoders = [\"FirstName\",\n",
        "                  \"LastName\",\n",
        "                  \"num\", \"GroupId\", ]\n",
        "onehot_encoders = [\"HomePlanet\", \"CryoSleep\",\n",
        "                   \"deck\", \"side\", \"Destination\", \"VIP\"]\n",
        "\n",
        "\n",
        "def fill_nulls(df):\n",
        "\n",
        "    # fill the null values with the mean, except for age -> set to 0\n",
        "    for i in float_features:\n",
        "        if i != \"Age\":\n",
        "            df[i] = df[i].fillna(0)\n",
        "        else:\n",
        "            df[i] = SimpleImputer(\n",
        "                strategy=\"mean\").fit_transform(df[[i]])\n",
        "\n",
        "    # label encoding and one hot encoding\n",
        "    for j in label_encoders:\n",
        "        df[j] = LabelEncoder().fit_transform(df[j])\n",
        "    for k in onehot_encoders:\n",
        "        df[k] = OneHotEncoder().fit_transform(df[[i]]).toarray()\n",
        "    return df\n",
        "\n",
        "\n",
        "def feature_engineering(df):\n",
        "\n",
        "    # calculate the most, least, std, and total spent for each person\n",
        "    df[\"most_spent\"] = df[[\"RoomService\",\n",
        "                           \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]].max(axis=1)\n",
        "    df[\"least_spent\"] = df[[\"RoomService\",\n",
        "                            \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]].min(axis=1)\n",
        "    df[\"std_spent\"] = df[[\"RoomService\",\n",
        "                          \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]].std(axis=1)\n",
        "    df[\"total_spent\"] = df[[\"RoomService\",\n",
        "                            \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]].sum(axis=1)\n",
        "\n",
        "    # split the cabin into three features\n",
        "    df[['deck', 'num', 'side']] = df['Cabin'].str.split('/', expand=True)\n",
        "    df = df.drop(columns=[\"Cabin\", ])\n",
        "\n",
        "    # if the person is sleeping or less than 12, make the total spend amounts 0\n",
        "    df['total_spent'] = df.apply(\n",
        "        lambda row: 0 if row[\"CryoSleep\"] == True or row[\"Age\"] <= 12 else row['total_spent'],\n",
        "        axis=1\n",
        "    )\n",
        "    df['most_spent'] = df.apply(\n",
        "        lambda row: 0 if row[\"CryoSleep\"] == True or row[\"Age\"] <= 12 else row['most_spent'],\n",
        "        axis=1\n",
        "    )\n",
        "    df['least_spent'] = df.apply(\n",
        "        lambda row: 0 if row[\"CryoSleep\"] == True or row[\"Age\"] <= 12 else row['least_spent'],\n",
        "        axis=1\n",
        "    )\n",
        "    df['std_spent'] = df.apply(\n",
        "        lambda row: 0 if row[\"CryoSleep\"] == True or row[\"Age\"] <= 12 else row['std_spent'],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # split name into first and last name\n",
        "    df['FirstName'] = df['Name'].str.split(' ', expand=True)[0]\n",
        "    df['LastName'] = df['Name'].str.split(' ', expand=True)[1]\n",
        "    df.drop(columns=['Name'], inplace=True)\n",
        "\n",
        "    # split travelers into groups based on their id\n",
        "    df['GroupId'] = df['PassengerId'].str.split('_', expand=True)[\n",
        "        0]\n",
        "    return df\n",
        "\n",
        "\n",
        "# transform the training and test data\n",
        "x_train = feature_engineering(x_train)\n",
        "x_train = fill_nulls(x_train)\n",
        "x_train = x_train.drop(columns=['PassengerId'])\n",
        "\n",
        "x_test = feature_engineering(x_test)\n",
        "x_test = fill_nulls(x_test)\n",
        "x_test = x_test.drop(columns=['PassengerId'])\n",
        "\n",
        "# number of features\n",
        "feature_names = x_train.columns\n",
        "print(\"Number of features: \", len(feature_names))\n",
        "\n",
        "y_preds = []\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=5)\n",
        "for fold, (train_id, test_id) in enumerate(skfold.split(x_train, y_train)):\n",
        "\n",
        "    # split into the folds\n",
        "    X_train = x_train.iloc[train_id]\n",
        "    Y_train = y_train.iloc[train_id]\n",
        "    X_test = x_train.iloc[test_id]\n",
        "    Y_test = y_train.iloc[test_id]\n",
        "\n",
        "    X_train = np.asarray(X_train).astype('float32')\n",
        "    X_test = np.asarray(X_test).astype('float32')\n",
        "    Y_train = np.asarray(Y_train).astype('float32')\n",
        "    Y_test = np.asarray(Y_test).astype('float32')\n",
        "\n",
        "    # # run the model on the fold\n",
        "    model = RandomForestClassifier(n_estimators=500, max_depth=5)\n",
        "    model.fit(X_train, Y_train)\n",
        "    print(f\"Model score: {model.score(X_test, Y_test)}\")\n",
        "    pred = model.predict(x_test)\n",
        "    y_preds.append(pred)\n",
        "\n",
        "pred = sum(y_preds) / len(y_preds)\n",
        "submission['Transported'] = pred\n",
        "submission['Transported'] = np.where(\n",
        "    submission['Transported'] > 0.5, True, False)\n",
        "\n",
        "os.makedirs('submissions/random_forests', exist_ok=True)\n",
        "submission.to_csv('submissions/random_forests/out.csv', index=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz_39YI-O6FB",
        "outputId": "9d6e513c-3a4b-419f-d637-54fc73e83f78"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features:  20\n",
            "Model score: 0.5146635997699828\n",
            "Model score: 0.7613571017826337\n",
            "Model score: 0.7648073605520413\n",
            "Model score: 0.7888377445339471\n",
            "Model score: 0.6680092059838896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xQsAQc5NO6H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KefOovILO6Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DKpGL6BCO6NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "750Qacl4O6QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g0pWFNXiO6TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "htsWPF6BO6WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IFJm43CCO6Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mMXAtNhBO6b5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}